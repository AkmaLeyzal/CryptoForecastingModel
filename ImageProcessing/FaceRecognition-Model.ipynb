{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41Tj4a-bT4U5"
      },
      "source": [
        "## **Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a3t792tUK1H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_duqxIZ5UF8y"
      },
      "source": [
        "## **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OteCDLDgUWqn"
      },
      "outputs": [],
      "source": [
        "csv_path = '/content/drive/MyDrive/PCD 2025/datasetPCD/Dataset.csv'\n",
        "training_folder = '/content/drive/MyDrive/PCD 2025/datasetPCD/Original Images/Original Images'\n",
        "testing_folder = '/content/drive/MyDrive/PCD 2025/datasetPCD/Faces/Faces'\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nUnique Labels:\", df['label'].nunique())\n",
        "print(\"\\nLabel Distribution:\")\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "def load_images_from_folder(folder_path, label_df):\n",
        "    images = []\n",
        "    labels = []\n",
        "    image_names = []\n",
        "\n",
        "    for artist_folder in os.listdir(folder_path):\n",
        "        artist_path = os.path.join(folder_path, artist_folder)\n",
        "\n",
        "        if os.path.isdir(artist_path):\n",
        "            for img_name in os.listdir(artist_path):\n",
        "                img_path = os.path.join(artist_path, img_name)\n",
        "\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                    images.append(gray)\n",
        "                    labels.append(artist_folder)\n",
        "                    image_names.append(img_name)\n",
        "\n",
        "    return images, labels, image_names\n",
        "\n",
        "train_images, train_labels, train_names = load_images_from_folder(training_folder, df)\n",
        "print(f\"Total training images loaded: {len(train_images)}\")\n",
        "print(f\"Unique artists: {len(set(train_labels))}\")\n",
        "\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# df['label'].value_counts().plot(kind='bar')\n",
        "# plt.title('Distribusi Artis dalam Dataset')\n",
        "# plt.xlabel('Nama Artis')\n",
        "# plt.ylabel('Jumlah Gambar')\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxHSATCIUGNG"
      },
      "source": [
        "## **EDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vqf9IE8VuW4"
      },
      "outputs": [],
      "source": [
        "# 2. ANALISIS DISTRIBUSI LABEL\n",
        "print(\"\\n\\n2. ANALISIS DISTRIBUSI LABEL\")\n",
        "print(\"-\"*40)\n",
        "label_counts = df['label'].value_counts().sort_index()\n",
        "unique_labels = df['label'].nunique()\n",
        "\n",
        "print(f\"✓ Jumlah kelas/individu unik: {unique_labels}\")\n",
        "print(f\"✓ Total sampel per kelas:\")\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"   - {label}: {count} gambar\")\n",
        "\n",
        "# Statistik distribusi\n",
        "print(f\"\\nStatistik distribusi:\")\n",
        "print(f\"   - Rata-rata sampel per kelas: {label_counts.mean():.2f}\")\n",
        "print(f\"   - Median sampel per kelas: {label_counts.median():.2f}\")\n",
        "print(f\"   - Std deviasi: {label_counts.std():.2f}\")\n",
        "print(f\"   - Min sampel: {label_counts.min()}\")\n",
        "print(f\"   - Max sampel: {label_counts.max()}\")\n",
        "\n",
        "# 3. CEK KEBERADAAN FILE GAMBAR\n",
        "print(\"\\n\\n3. VALIDASI KEBERADAAN FILE GAMBAR\")\n",
        "print(\"-\"*40)\n",
        "missing_images = []\n",
        "existing_images = []\n",
        "corrupted_images = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    image_path = os.path.join(img_folder, row['id'])\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        missing_images.append((idx, row['id'], row['label']))\n",
        "    else:\n",
        "        # Cek apakah gambar bisa dibaca\n",
        "        try:\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                corrupted_images.append((idx, row['id'], row['label']))\n",
        "            else:\n",
        "                existing_images.append((idx, row['id'], row['label']))\n",
        "        except:\n",
        "            corrupted_images.append((idx, row['id'], row['label']))\n",
        "\n",
        "print(f\"✓ Gambar yang tersedia: {len(existing_images)}\")\n",
        "print(f\"✗ Gambar yang hilang: {len(missing_images)}\")\n",
        "print(f\"✗ Gambar yang corrupt: {len(corrupted_images)}\")\n",
        "\n",
        "if missing_images:\n",
        "    print(f\"\\nContoh gambar yang hilang:\")\n",
        "    for i, (idx, img_id, label) in enumerate(missing_images[:5]):\n",
        "        print(f\"   - Index {idx}: {img_id} (Label: {label})\")\n",
        "\n",
        "# 4. ANALISIS RESOLUSI GAMBAR\n",
        "print(\"\\n\\n4. ANALISIS RESOLUSI GAMBAR\")\n",
        "print(\"-\"*40)\n",
        "resolutions = []\n",
        "file_sizes = []\n",
        "\n",
        "for idx, img_id, label in existing_images:\n",
        "    image_path = os.path.join(img_folder, img_id)\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    resolutions.append(img.shape)\n",
        "    file_sizes.append(os.path.getsize(image_path))\n",
        "\n",
        "if resolutions:\n",
        "    unique_resolutions = list(set(resolutions))\n",
        "    print(f\"✓ Resolusi unik yang ditemukan: {len(unique_resolutions)}\")\n",
        "\n",
        "    resolution_counts = Counter(resolutions)\n",
        "    print(f\"✓ Distribusi resolusi:\")\n",
        "    for res, count in sorted(resolution_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"   - {res[1]}x{res[0]}: {count} gambar ({count/len(resolutions)*100:.1f}%)\")\n",
        "\n",
        "    # Statistik resolusi\n",
        "    heights = [res[0] for res in resolutions]\n",
        "    widths = [res[1] for res in resolutions]\n",
        "\n",
        "    print(f\"\\nStatistik resolusi:\")\n",
        "    print(f\"   - Tinggi: min={min(heights)}, max={max(heights)}, rata-rata={np.mean(heights):.1f}\")\n",
        "    print(f\"   - Lebar: min={min(widths)}, max={max(widths)}, rata-rata={np.mean(widths):.1f}\")\n",
        "\n",
        "# 5. ANALISIS KUALITAS GAMBAR\n",
        "print(\"\\n\\n5. ANALISIS KUALITAS GAMBAR\")\n",
        "print(\"-\"*40)\n",
        "brightness_stats = []\n",
        "contrast_stats = []\n",
        "blur_stats = []\n",
        "\n",
        "sample_size = min(100, len(existing_images))  # Analisis sample untuk efisiensi\n",
        "print(f\"Menganalisis kualitas dari {sample_size} gambar sample...\")\n",
        "\n",
        "for i in range(sample_size):\n",
        "    idx, img_id, label = existing_images[i]\n",
        "    image_path = os.path.join(img_folder, img_id)\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Brightness (rata-rata intensitas pixel)\n",
        "    brightness = np.mean(img)\n",
        "    brightness_stats.append(brightness)\n",
        "\n",
        "    # Contrast (standar deviasi intensitas pixel)\n",
        "    contrast = np.std(img)\n",
        "    contrast_stats.append(contrast)\n",
        "\n",
        "    # Blur detection (varian Laplacian)\n",
        "    blur_score = cv2.Laplacian(img, cv2.CV_64F).var()\n",
        "    blur_stats.append(blur_score)\n",
        "\n",
        "if brightness_stats:\n",
        "    print(f\"✓ Statistik Kecerahan:\")\n",
        "    print(f\"   - Rata-rata: {np.mean(brightness_stats):.1f}\")\n",
        "    print(f\"   - Min: {np.min(brightness_stats):.1f}, Max: {np.max(brightness_stats):.1f}\")\n",
        "\n",
        "    print(f\"✓ Statistik Kontras:\")\n",
        "    print(f\"   - Rata-rata: {np.mean(contrast_stats):.1f}\")\n",
        "    print(f\"   - Min: {np.min(contrast_stats):.1f}, Max: {np.max(contrast_stats):.1f}\")\n",
        "\n",
        "    print(f\"✓ Statistik Blur (semakin tinggi = semakin tajam):\")\n",
        "    print(f\"   - Rata-rata: {np.mean(blur_stats):.1f}\")\n",
        "    print(f\"   - Min: {np.min(blur_stats):.1f}, Max: {np.max(blur_stats):.1f}\")\n",
        "\n",
        "    # Identifikasi gambar bermasalah\n",
        "    very_dark = sum(1 for b in brightness_stats if b < 50)\n",
        "    very_bright = sum(1 for b in brightness_stats if b > 200)\n",
        "    low_contrast = sum(1 for c in contrast_stats if c < 20)\n",
        "    very_blurry = sum(1 for bl in blur_stats if bl < 100)\n",
        "\n",
        "    print(f\"\\n⚠️  Potensi masalah kualitas:\")\n",
        "    print(f\"   - Gambar terlalu gelap (< 50): {very_dark}\")\n",
        "    print(f\"   - Gambar terlalu terang (> 200): {very_bright}\")\n",
        "    print(f\"   - Kontras rendah (< 20): {low_contrast}\")\n",
        "    print(f\"   - Gambar blur (< 100): {very_blurry}\")\n",
        "\n",
        "# 6. ANALISIS CLASS IMBALANCE\n",
        "print(\"\\n\\n6. ANALISIS KESEIMBANGAN KELAS\")\n",
        "print(\"-\"*40)\n",
        "class_proportions = df['label'].value_counts(normalize=True).sort_index()\n",
        "\n",
        "print(f\"✓ Proporsi setiap kelas:\")\n",
        "for label, prop in class_proportions.items():\n",
        "    print(f\"   - {label}: {prop:.3f} ({prop*100:.1f}%)\")\n",
        "\n",
        "# Hitung imbalance ratio\n",
        "max_samples = label_counts.max()\n",
        "min_samples = label_counts.min()\n",
        "imbalance_ratio = max_samples / min_samples\n",
        "\n",
        "print(f\"\\n✓ Analisis keseimbangan:\")\n",
        "print(f\"   - Rasio ketidakseimbangan: {imbalance_ratio:.2f}:1\")\n",
        "if imbalance_ratio > 2:\n",
        "    print(f\"   ⚠️  Dataset tidak seimbang - pertimbangkan teknik balancing\")\n",
        "else:\n",
        "    print(f\"   ✓ Dataset relatif seimbang\")\n",
        "\n",
        "# 7. VISUALISASI\n",
        "print(\"\\n\\n7. MEMBUAT VISUALISASI\")\n",
        "print(\"-\"*40)\n",
        "\n",
        "# Visualisasi 1: Distribusi Label\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2, 2, 1)\n",
        "label_counts.plot(kind='bar', color='skyblue', alpha=0.7)\n",
        "plt.title(\"Distribusi Jumlah Gambar per Individu\", fontsize=12, fontweight='bold')\n",
        "plt.xlabel(\"Label (Individu)\")\n",
        "plt.ylabel(\"Jumlah Gambar\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Visualisasi 2: Distribusi Resolusi\n",
        "if resolutions:\n",
        "    plt.subplot(2, 2, 2)\n",
        "    heights = [res[0] for res in resolutions]\n",
        "    widths = [res[1] for res in resolutions]\n",
        "    plt.scatter(widths, heights, alpha=0.6, c='coral')\n",
        "    plt.title(\"Distribusi Resolusi Gambar\", fontsize=12, fontweight='bold')\n",
        "    plt.xlabel(\"Lebar (pixels)\")\n",
        "    plt.ylabel(\"Tinggi (pixels)\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Visualisasi 3: Distribusi Kualitas Gambar\n",
        "if brightness_stats:\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.hist(brightness_stats, bins=20, color='lightgreen', alpha=0.7, edgecolor='black')\n",
        "    plt.title(\"Distribusi Kecerahan Gambar\", fontsize=12, fontweight='bold')\n",
        "    plt.xlabel(\"Nilai Kecerahan\")\n",
        "    plt.ylabel(\"Frekuensi\")\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Visualisasi 4: Class Balance\n",
        "plt.subplot(2, 2, 4)\n",
        "colors = plt.cm.Set3(np.linspace(0, 1, len(class_proportions)))\n",
        "plt.pie(class_proportions.values, labels=class_proportions.index, autopct='%1.1f%%',\n",
        "        colors=colors, startangle=90)\n",
        "plt.title(\"Proporsi Kelas\", fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 8. MENAMPILKAN CONTOH GAMBAR\n",
        "print(\"\\n8. CONTOH GAMBAR DARI DATASET\")\n",
        "print(\"-\"*40)\n",
        "\n",
        "if existing_images:\n",
        "    # Tampilkan contoh dari setiap kelas\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    samples_per_class = {}\n",
        "    for idx, img_id, label in existing_images:\n",
        "        if label not in samples_per_class:\n",
        "            samples_per_class[label] = []\n",
        "        if len(samples_per_class[label]) < 3:  # Maksimal 3 contoh per kelas\n",
        "            samples_per_class[label].append((img_id, idx))\n",
        "\n",
        "    plot_idx = 1\n",
        "    for label, samples in samples_per_class.items():\n",
        "        for img_id, idx in samples:\n",
        "            if plot_idx > 15:  # Batasi tampilan\n",
        "                break\n",
        "\n",
        "            image_path = os.path.join(img_folder, img_id)\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            plt.subplot(3, 5, plot_idx)\n",
        "            plt.imshow(img, cmap='gray')\n",
        "            plt.title(f\"Label: {label}\\nSize: {img.shape}\", fontsize=8)\n",
        "            plt.axis('off')\n",
        "            plot_idx += 1\n",
        "\n",
        "        if plot_idx > 15:\n",
        "            break\n",
        "\n",
        "    plt.suptitle(\"Contoh Gambar dari Setiap Kelas\", fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gA9JlbYUGRw"
      },
      "source": [
        "## **Preprocessing and Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_aq6RBhXYMN"
      },
      "source": [
        "### **Face Detection dan Cropping**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeZi633WX0M9"
      },
      "outputs": [],
      "source": [
        "def detect_and_crop_face(image):\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    if len(faces) > 0:\n",
        "        (x, y, w, h) = faces[0]\n",
        "        padding = int(0.1 * w)\n",
        "        y1 = max(0, y - padding)\n",
        "        y2 = min(image.shape[0], y + h + padding)\n",
        "        x1 = max(0, x - padding)\n",
        "        x2 = min(image.shape[1], x + w + padding)\n",
        "\n",
        "        face_crop = image[y1:y2, x1:x2]\n",
        "        return face_crop\n",
        "    else:\n",
        "        return image\n",
        "\n",
        "print(\"Detecting and cropping faces...\")\n",
        "cropped_faces = []\n",
        "valid_labels = []\n",
        "valid_names = []\n",
        "\n",
        "for i, (img, label, name) in enumerate(zip(train_images, train_labels, train_names)):\n",
        "    face = detect_and_crop_face(img)\n",
        "    if face is not None and face.size > 0:\n",
        "        cropped_faces.append(face)\n",
        "        valid_labels.append(label)\n",
        "        valid_names.append(name)\n",
        "\n",
        "    if (i + 1) % 100 == 0:\n",
        "        print(f\"Processed {i + 1}/{len(train_images)} images\")\n",
        "\n",
        "print(f\"Successfully cropped {len(cropped_faces)} faces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY4yi0Seg4xs"
      },
      "source": [
        "### **Data Augmented**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jToitcOng8sj"
      },
      "outputs": [],
      "source": [
        "def augment_data(images, labels):\n",
        "    augmented_images = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    for img, label in zip(images, labels):\n",
        "        augmented_images.append(img)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "        flipped = cv2.flip(img, 1)\n",
        "        augmented_images.append(flipped)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "        bright = cv2.convertScaleAbs(img, alpha=1.2, beta=10)\n",
        "        dark = cv2.convertScaleAbs(img, alpha=0.8, beta=-10)\n",
        "        augmented_images.append(bright)\n",
        "        augmented_labels.append(label)\n",
        "        augmented_images.append(dark)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "    return augmented_images, augmented_labels\n",
        "\n",
        "print(\"Augmenting data...\")\n",
        "augmented_faces, augmented_labels = augment_data(cropped_faces, valid_labels)\n",
        "print(f\"Augmented data size: {len(augmented_faces)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6TydvCKXzOq"
      },
      "source": [
        "### **Resize Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXjHcIzlYr_F"
      },
      "outputs": [],
      "source": [
        "def resize_images(images, size=(128, 128)):\n",
        "    resized_images = []\n",
        "    for img in images:\n",
        "        resized = cv2.resize(img, size)\n",
        "        resized_images.append(resized)\n",
        "    return np.array(resized_images)\n",
        "\n",
        "resized_faces = resize_images(augmented_faces)\n",
        "print(f\"Resized faces shape: {resized_faces.shape}\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < len(resized_faces):\n",
        "        ax.imshow(resized_faces[i], cmap='gray')\n",
        "        ax.set_title(valid_labels[i])\n",
        "        ax.axis('off')\n",
        "plt.suptitle('Sample Cropped and Resized Faces')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgGeo9yYXzWj"
      },
      "source": [
        "### **Local Binary Pattern (LBP) Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCx2AfFvZNhI"
      },
      "outputs": [],
      "source": [
        "def calculate_lbp(image, radius=1, n_points=8):\n",
        "    rows, cols = image.shape\n",
        "    lbp_image = np.zeros_like(image)\n",
        "\n",
        "    for i in range(radius, rows - radius):\n",
        "        for j in range(radius, cols - radius):\n",
        "            center = image[i, j]\n",
        "            binary_code = 0\n",
        "\n",
        "            for p in range(n_points):\n",
        "                theta = 2 * np.pi * p / n_points\n",
        "                neighbor_x = i + radius * np.cos(theta)\n",
        "                neighbor_y = j + radius * np.sin(theta)\n",
        "\n",
        "                x1, y1 = int(neighbor_x), int(neighbor_y)\n",
        "                x2, y2 = x1 + 1, y1 + 1\n",
        "\n",
        "                x1 = max(0, min(x1, rows - 1))\n",
        "                x2 = max(0, min(x2, rows - 1))\n",
        "                y1 = max(0, min(y1, cols - 1))\n",
        "                y2 = max(0, min(y2, cols - 1))\n",
        "\n",
        "                fx = neighbor_x - x1\n",
        "                fy = neighbor_y - y1\n",
        "\n",
        "                neighbor_value = (1 - fx) * (1 - fy) * image[x1, y1] + \\\n",
        "                                fx * (1 - fy) * image[x2, y1] + \\\n",
        "                                (1 - fx) * fy * image[x1, y2] + \\\n",
        "                                fx * fy * image[x2, y2]\n",
        "\n",
        "                if neighbor_value >= center:\n",
        "                    binary_code |= (1 << p)\n",
        "\n",
        "            lbp_image[i, j] = binary_code\n",
        "\n",
        "    return lbp_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD1DdI9jh_oa"
      },
      "source": [
        "#### **Visualize LBP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8nhKAidiE0b"
      },
      "outputs": [],
      "source": [
        "def visualize_lbp(image):\n",
        "    lbp_image = calculate_lbp(image)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    axes[0].imshow(image, cmap='gray')\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(lbp_image, cmap='gray')\n",
        "    axes[1].set_title('LBP Image')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_lbp(resized_faces)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5fRhFvIXzZQ"
      },
      "source": [
        "### **Local Binary Pattern Histogram (LBPH) Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgxjK92TZa8k"
      },
      "outputs": [],
      "source": [
        "def calculate_lbph(image, radius=1, n_points=8, grid_x=8, grid_y=8):\n",
        "    lbp_image = calculate_lbp(image, radius, n_points)\n",
        "\n",
        "    height, width = lbp_image.shape\n",
        "    grid_height = height // grid_y\n",
        "    grid_width = width // grid_x\n",
        "\n",
        "    histograms = []\n",
        "\n",
        "    for i in range(grid_y):\n",
        "        for j in range(grid_x):\n",
        "            y1 = i * grid_height\n",
        "            y2 = (i + 1) * grid_height if i < grid_y - 1 else height\n",
        "            x1 = j * grid_width\n",
        "            x2 = (j + 1) * grid_width if j < grid_x - 1 else width\n",
        "\n",
        "            grid = lbp_image[y1:y2, x1:x2]\n",
        "\n",
        "            hist, _ = np.histogram(grid, bins=2**n_points, range=(0, 2**n_points))\n",
        "            histograms.append(hist)\n",
        "\n",
        "    feature_vector = np.concatenate(histograms)\n",
        "\n",
        "    feature_vector = feature_vector / (feature_vector.sum() + 1e-7)\n",
        "\n",
        "    return feature_vector\n",
        "\n",
        "print(\"Extracting LBPH features...\")\n",
        "lbph_features = []\n",
        "for i, face in enumerate(resized_faces):\n",
        "    features = calculate_lbph(face, radius=1, n_points=8, grid_x=8, grid_y=8)\n",
        "    lbph_features.append(features)\n",
        "\n",
        "    if (i + 1) % 50 == 0:\n",
        "        print(f\"Extracted features for {i + 1}/{len(resized_faces)} images\")\n",
        "\n",
        "lbph_features = np.array(lbph_features)\n",
        "print(f\"LBPH features shape: {lbph_features.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j86c8FYZToS"
      },
      "source": [
        "### **Label Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqn8-pk0Zp6X"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(augmented_labels)  # Ganti dari valid_labels\n",
        "print(f\"Number of classes: {len(label_encoder.classes_)}\")\n",
        "print(f\"Classes: {label_encoder.classes_}\")\n",
        "print(f\"Number of encoded labels: {len(encoded_labels)}\")  # Tambahkan ini untuk verifikasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWdN2Vz7XzpE"
      },
      "source": [
        "### **Data Split for Training and Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03rsCg_IXKKQ"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    lbph_features, encoded_labels, test_size=0.2, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Validation set size: {X_val.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqPA5yIqUGVD"
      },
      "source": [
        "## **Features Selection Using PCA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV00a8JRbGjc"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=0.9)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_val_pca = pca.transform(X_val)\n",
        "\n",
        "print(f\"Original features: {X_train.shape[1]}\")\n",
        "print(f\"PCA features: {X_train_pca.shape[1]}\")\n",
        "print(f\"Variance explained: {pca.explained_variance_ratio_.sum():.2%}\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "cumsum_var = np.cumsum(pca.explained_variance_ratio_)\n",
        "plt.plot(range(1, len(cumsum_var) + 1), cumsum_var)\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('PCA Explained Variance')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBkrP0rmUGX8"
      },
      "source": [
        "## **Training Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnZYQiJYinPY"
      },
      "source": [
        "### **Support Vector Classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o2TduC4jPeo"
      },
      "outputs": [],
      "source": [
        "print(\"Training SVC model...\")\n",
        "svm_model = SVC(kernel='rbf', C=10, gamma='scale', random_state=901)\n",
        "svm_model.fit(X_train_pca, y_train)\n",
        "svm_pred = svm_model.predict(X_val_pca)\n",
        "svm_accuracy = accuracy_score(y_val, svm_pred)\n",
        "print(f\"SVC Accuracy: {svm_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkg0AiMcir53"
      },
      "source": [
        "### **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIFQMVLOjYF7"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTraining Random Forest model...\")\n",
        "rf_model = RandomForestClassifier(n_estimators=200, random_state=901, n_jobs=-1)\n",
        "rf_model.fit(X_train_pca, y_train)\n",
        "rf_pred = rf_model.predict(X_val_pca)\n",
        "rf_accuracy = accuracy_score(y_val, rf_pred)\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWEGHc5LisGF"
      },
      "source": [
        "### **KNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tgrs7YlhjaH3"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTraining KNN model...\")\n",
        "knn_model = KNeighborsClassifier(n_neighbors=7, metric='cosine')\n",
        "knn_model.fit(X_train_pca, y_train)\n",
        "knn_pred = knn_model.predict(X_val_pca)\n",
        "knn_accuracy = accuracy_score(y_val, knn_pred)\n",
        "print(f\"KNN Accuracy: {knn_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u95m9HHMUGku"
      },
      "source": [
        "## **Validation Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx00I4D1ltV5"
      },
      "source": [
        "### **RF Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r3a65q_lpPH"
      },
      "outputs": [],
      "source": [
        "best_model = rf_model\n",
        "best_pred = rf_pred\n",
        "best_accuracy = rf_accuracy\n",
        "\n",
        "print(f\"\\nBest Model: RF with accuracy {best_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, best_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_val, best_pred)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCyTXxanlsHu"
      },
      "source": [
        "### **KNN Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-boBXERNlp_A"
      },
      "outputs": [],
      "source": [
        "best_model = knn_model\n",
        "best_pred = knn_pred\n",
        "best_accuracy = knn_accuracy\n",
        "\n",
        "print(f\"\\nBest Model: KNN with accuracy {best_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, best_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_val, best_pred)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJTetDTZllNB"
      },
      "source": [
        "### **SVC Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xj_LmYB9jrtf"
      },
      "outputs": [],
      "source": [
        "best_model = svm_model\n",
        "best_pred = svm_pred\n",
        "best_accuracy = svm_accuracy\n",
        "\n",
        "print(f\"\\nBest Model: SVM with accuracy {best_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, best_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_val, best_pred)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylCH34FPUGoH"
      },
      "source": [
        "## **Testing Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nfjr6RuoIGF"
      },
      "source": [
        "### **Load Testing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbVNkf6poOBd"
      },
      "outputs": [],
      "source": [
        "def load_test_images(test_folder):\n",
        "    test_images = []\n",
        "    test_names = []\n",
        "\n",
        "    for img_name in os.listdir(test_folder):\n",
        "        img_path = os.path.join(test_folder, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is not None:\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            test_images.append(gray)\n",
        "            test_names.append(img_name)\n",
        "\n",
        "    return test_images, test_names\n",
        "\n",
        "print(\"Loading test images...\")\n",
        "test_images, test_names = load_test_images(testing_folder)\n",
        "print(f\"Loaded {len(test_images)} test images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7fq7sacoW10"
      },
      "source": [
        "### **Data Preparation for Testing Set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJe1sWI1og-W"
      },
      "outputs": [],
      "source": [
        "test_cropped = []\n",
        "valid_test_names = []\n",
        "\n",
        "for img, name in zip(test_images, test_names):\n",
        "    face = detect_and_crop_face(img)\n",
        "    if face is not None and face.size > 0:\n",
        "        test_cropped.append(face)\n",
        "        valid_test_names.append(name)\n",
        "\n",
        "test_resized = resize_images(test_cropped)\n",
        "\n",
        "print(\"Extracting features from test images...\")\n",
        "test_features = []\n",
        "for face in test_resized:\n",
        "    features = calculate_lbph(face, radius=1, n_points=8, grid_x=8, grid_y=8)\n",
        "    test_features.append(features)\n",
        "\n",
        "test_features = np.array(test_features)\n",
        "\n",
        "test_features_pca = pca.transform(test_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIp2Kj0pofbj"
      },
      "source": [
        "### **Predict Test Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t8lwMowo48E"
      },
      "outputs": [],
      "source": [
        "test_predictions = best_model.predict(test_features_pca)\n",
        "test_pred_labels = label_encoder.inverse_transform(test_predictions)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'image_name': valid_test_names,\n",
        "    'predicted_artist': test_pred_labels\n",
        "})\n",
        "\n",
        "print(\"\\nTest Results:\")\n",
        "print(results_df.head(10))\n",
        "\n",
        "results_df.to_csv('test_predictions.csv', index=False)\n",
        "print(\"\\nPredictions saved to 'test_predictions.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF-HhY__ofu8"
      },
      "source": [
        "### **Visualize Test Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9o8o3pDpHzm"
      },
      "outputs": [],
      "source": [
        "n_samples = min(10, len(test_resized))\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < n_samples:\n",
        "        ax.imshow(test_resized[i], cmap='gray')\n",
        "        ax.set_title(f\"Predicted: {test_pred_labels[i]}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.suptitle('Sample Test Predictions')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95VcfPkQpHTE"
      },
      "source": [
        "### **Ensemble Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7BlrMkepU30"
      },
      "outputs": [],
      "source": [
        "ensemble_pred = np.zeros((len(X_val_pca), len(label_encoder.classes_)))\n",
        "\n",
        "weights = {'svm': 0.5, 'rf': 0.4, 'knn': 0.1}\n",
        "\n",
        "svm_proba = svm_model.decision_function(X_val_pca)\n",
        "rf_proba = rf_model.predict_proba(X_val_pca)\n",
        "knn_proba = knn_model.predict_proba(X_val_pca)\n",
        "\n",
        "svm_proba_norm = np.exp(svm_proba) / np.sum(np.exp(svm_proba), axis=1, keepdims=True)\n",
        "\n",
        "ensemble_proba = (weights['svm'] * svm_proba_norm +\n",
        "                  weights['rf'] * rf_proba +\n",
        "                  weights['knn'] * knn_proba)\n",
        "\n",
        "ensemble_pred = np.argmax(ensemble_proba, axis=1)\n",
        "ensemble_accuracy = accuracy_score(y_val, ensemble_pred)\n",
        "\n",
        "print(f\"\\nEnsemble Model Accuracy: {ensemble_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POIzsP8dpla0"
      },
      "outputs": [],
      "source": [
        "# # Cell 20: Save Final Model\n",
        "# import pickle\n",
        "\n",
        "# # Save the best model\n",
        "# with open('face_recognition_model.pkl', 'wb') as f:\n",
        "#     pickle.dump(best_model, f)\n",
        "\n",
        "# # Save the PCA transformer\n",
        "# with open('pca_transformer.pkl', 'wb') as f:\n",
        "#     pickle.dump(pca, f)\n",
        "\n",
        "# # Save the label encoder\n",
        "# with open('label_encoder.pkl', 'wb') as f:\n",
        "#     pickle.dump(label_encoder, f)\n",
        "\n",
        "# print(\"Models saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx4n46aVpncg"
      },
      "source": [
        "## **Performance Metric Summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnXsIA_jp4Hr"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== PERFORMANCE SUMMARY ===\")\n",
        "print(f\"Total Images Processed: {len(resized_faces)}\")\n",
        "print(f\"Number of Classes: {len(label_encoder.classes_)}\")\n",
        "print(f\"Feature Dimension (Original): {lbph_features.shape[1]}\")\n",
        "print(f\"Feature Dimension (After PCA): {X_train_pca.shape[1]}\")\n",
        "print(f\"\\nModel Accuracies:\")\n",
        "print(f\"- SVM: {svm_accuracy:.4f}\")\n",
        "print(f\"- Random Forest: {rf_accuracy:.4f}\")\n",
        "print(f\"- KNN: {knn_accuracy:.4f}\")\n",
        "print(f\"- Ensemble: {ensemble_accuracy:.4f}\")\n",
        "print(f\"\\nBest Model: {'Ensemble' if ensemble_accuracy > best_accuracy else 'SVM'}\")\n",
        "print(f\"Best Accuracy: {max(ensemble_accuracy, best_accuracy):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0EgwgO2xtPU"
      },
      "outputs": [],
      "source": [
        "# Feature Importance Analysis (untuk Random Forest)\n",
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Plot top 20 features\n",
        "top_features_idx = np.argsort(feature_importances)[-20:]\n",
        "top_features_importance = feature_importances[top_features_idx]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(range(len(top_features_idx)), top_features_importance)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature Index')\n",
        "plt.title('Top 20 Most Important Features (Random Forest)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
